{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analyst Skills Analysis: Job Data Collection (JSearch API)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.1 Project goals and objectives\n",
        "\n",
        "**Goal:**  \n",
        "Collect job posting data for *data analyst* and *junior data analyst* roles across major English-speaking markets using the **JSearch API** (via RapidAPI).\n",
        "\n",
        "**Key objectives:**\n",
        "- Define a reusable function to search for jobs with pagination;\n",
        "- Configure target countries, locations, and roles;\n",
        "- Fetch and convert API responses into DataFrames;\n",
        "- Combine and save the dataset to CSV;\n",
        "- Run sanity checks on the collected data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.2 Data description\n",
        "\n",
        "**Source:** Job postings from the **JSearch API** ([RapidAPI](https://rapidapi.com/letscrape-6bRBa3QguO5/api/jsearch)), which aggregates listings from Google for Jobs, pulling data from LinkedIn, Indeed, Glassdoor, ZipRecruiter, and other job boards.\n",
        "\n",
        "**Markets:** USA, United Kingdom, Canada. These countries were chosen because:\n",
        "- All postings are in English, enabling consistent skill extraction via keyword matching;\n",
        "- They represent the largest English-speaking job markets for data analysts;\n",
        "- JSearch provides good coverage for these regions.\n",
        "\n",
        "**Roles:** *data analyst*, *junior data analyst*.\n",
        "\n",
        "**Time window:** Only postings from the last month are collected (18 Jan – 17 Feb 2026). Since the goal is to identify *currently* in-demand skills rather than track trends over time, a one-month snapshot provides a representative and up-to-date picture of the market.\n",
        "\n",
        "**Location granularity:** Queries are split by major cities and states to maximise coverage, since Google for Jobs returns ~50–100 results per unique query.\n",
        "\n",
        "**Output:** \n",
        "- `jsearch_all_countries_roles.csv` — combined dataset with all jobs;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.3 Project structure\n",
        "\n",
        "- [1. Defining the job search function](#section-1)\n",
        "- [2. Defining target locations, roles and collection settings](#section-2)\n",
        "- [3. Converting API results into a DataFrame](#section-3)\n",
        "- [4. Fetching data for all location-role combinations and saving to CSV](#section-4)\n",
        "- [5. Quick sanity checks on the combined dataset](#section-5)\n",
        "- [6. Summary](#section-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "RAPIDAPI_KEY = os.getenv(\"RAPIDAPI_KEY\")\n",
        "\n",
        "if not RAPIDAPI_KEY:\n",
        "    raise ValueError(\n",
        "        \"Fill in RAPIDAPI_KEY in .env first.\\n\")\n",
        "\n",
        "JSEARCH_HOST = \"jsearch.p.rapidapi.com\"\n",
        "JSEARCH_URL = \"https://jsearch.p.rapidapi.com/search\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"X-RapidAPI-Key\": RAPIDAPI_KEY,\n",
        "    \"X-RapidAPI-Host\": JSEARCH_HOST,\n",
        "}\n",
        "\n",
        "print(\"API key loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-1\"></a>\n",
        "\n",
        "## 1. Defining the job search function\n",
        "\n",
        "We define a reusable function `fetch_jsearch_jobs` that sends GET requests to the JSearch `/search` endpoint.\n",
        "\n",
        "**How it works:**\n",
        "1. Takes a `query` string (e.g. `\"data analyst in New York\"`) and a `country` ISO code;\n",
        "2. Paginates through results — each page returns up to 10 jobs;\n",
        "3. Uses `num_pages` to fetch multiple pages per call (each page = 1 quota credit);\n",
        "4. Logs remaining quota after each request;\n",
        "5. Stops immediately on HTTP 429 (rate limit);\n",
        "6. Returns a flat list of all job dictionaries collected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_jsearch_jobs(\n",
        "    query: str,\n",
        "    num_pages: int = 3,\n",
        "    date_posted: str = \"month\",\n",
        "    country: str = None,\n",
        "    pause_seconds: float = 2.0,\n",
        ") -> list:\n",
        "    \"\"\"\n",
        "    Fetch job postings from JSearch API.\n",
        "\n",
        "    Args:\n",
        "        query: Full search query, e.g. 'data analyst in New York'.\n",
        "        num_pages: Pages per API call (10 results/page, each page = 1 credit).\n",
        "        date_posted: Time filter — 'all', 'today', '3days', 'week', 'month'.\n",
        "        country: Optional ISO country code for the 'country' API param.\n",
        "        pause_seconds: Pause between pagination calls.\n",
        "\n",
        "    Returns:\n",
        "        List of job posting dictionaries.\n",
        "    \"\"\"\n",
        "    all_jobs = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        params = {\n",
        "            \"query\": query,\n",
        "            \"page\": str(page),\n",
        "            \"num_pages\": str(num_pages),\n",
        "            \"date_posted\": date_posted,\n",
        "        }\n",
        "        if country:\n",
        "            params[\"country\"] = country\n",
        "\n",
        "        response = requests.get(JSEARCH_URL, headers=HEADERS, params=params)\n",
        "\n",
        "        # Log rate-limit headers from RapidAPI\n",
        "        remaining = response.headers.get(\"x-ratelimit-requests-remaining\", \"?\")\n",
        "        limit = response.headers.get(\"x-ratelimit-requests-limit\", \"?\")\n",
        "        print(f\"  [Quota] {remaining}/{limit} requests remaining\")\n",
        "\n",
        "        # On 429: stop immediately to conserve quota\n",
        "        if response.status_code == 429:\n",
        "            print(\"  [Rate limit 429] Stopping to save quota.\")\n",
        "            break\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"  [HTTP {response.status_code}] {response.text[:200]}\")\n",
        "            break\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if data.get(\"status\") != \"OK\":\n",
        "            error_msg = data.get(\"error\", {}).get(\"message\", \"Unknown error\")\n",
        "            print(f\"  [API Error] {error_msg}\")\n",
        "            break\n",
        "\n",
        "        jobs = data.get(\"data\", [])\n",
        "\n",
        "        if not jobs:\n",
        "            print(f\"  No more results at page {page}, stopping.\")\n",
        "            break\n",
        "\n",
        "        all_jobs.extend(jobs)\n",
        "        print(\n",
        "            f\"  Page {page} (num_pages={num_pages}): \"\n",
        "            f\"received {len(jobs)} jobs (total: {len(all_jobs)})\"\n",
        "        )\n",
        "\n",
        "        # If fewer results than expected, we've reached the end\n",
        "        if len(jobs) < num_pages * 10:\n",
        "            break\n",
        "\n",
        "        # Move to the next batch of pages\n",
        "        page += num_pages\n",
        "        time.sleep(pause_seconds)\n",
        "\n",
        "    return all_jobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-2\"></a>\n",
        "\n",
        "## 2. Defining target locations, roles and collection settings\n",
        "\n",
        "To maximise the number of collected postings, we query by **individual cities and states** instead of whole countries. Google for Jobs returns ~50–100 results per unique query, so splitting by location increases the total yield. Duplicates across overlapping queries are removed by `job_id` at the end.\n",
        "\n",
        "**Countries:** USA (10 locations), United Kingdom (5), Canada (3).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Locations:            18\n",
            "Roles:                2\n",
            "Total combinations:   36\n",
            "Max possible results: 1080\n"
          ]
        }
      ],
      "source": [
        "# Each tuple: (country_code, country_name, query_location, api_country)\n",
        "#   query_location: city/state appended to role → \"data analyst in {location}\"\n",
        "#   api_country:    ISO code passed as the 'country' API parameter\n",
        "\n",
        "LOCATIONS = [\n",
        "    # USA — 10 major states / metro areas\n",
        "    (\"us\", \"USA\", \"New York\", \"us\"),\n",
        "    (\"us\", \"USA\", \"California\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Texas\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Illinois\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Florida\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Virginia\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Massachusetts\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Georgia\", \"us\"),\n",
        "    (\"us\", \"USA\", \"Colorado\", \"us\"),\n",
        "    (\"us\", \"USA\", \"remote USA\", \"us\"),\n",
        "\n",
        "    # United Kingdom — 5 key locations\n",
        "    (\"gb\", \"United Kingdom\", \"London\", \"gb\"),\n",
        "    (\"gb\", \"United Kingdom\", \"Manchester\", \"gb\"),\n",
        "    (\"gb\", \"United Kingdom\", \"Birmingham UK\", \"gb\"),\n",
        "    (\"gb\", \"United Kingdom\", \"Edinburgh\", \"gb\"),\n",
        "    (\"gb\", \"United Kingdom\", \"remote UK\", \"gb\"),\n",
        "\n",
        "    # Canada — 3 key locations\n",
        "    (\"ca\", \"Canada\", \"Toronto\", \"ca\"),\n",
        "    (\"ca\", \"Canada\", \"Vancouver\", \"ca\"),\n",
        "    (\"ca\", \"Canada\", \"remote Canada\", \"ca\"),\n",
        "]\n",
        "\n",
        "ROLES = [\"data analyst\", \"junior data analyst\"]\n",
        "\n",
        "NUM_PAGES = 3        # pages per API call (10 results/page, 1 credit/page)\n",
        "DATE_POSTED = \"month\"  # only jobs posted within the last month\n",
        "\n",
        "# --- Budget summary ---\n",
        "total_combos = len(LOCATIONS) * len(ROLES)\n",
        "\n",
        "print(f\"Locations:            {len(LOCATIONS)}\")\n",
        "print(f\"Roles:                {len(ROLES)}\")\n",
        "print(f\"Total combinations:   {total_combos}\")\n",
        "print(f\"Max possible results: {total_combos * NUM_PAGES * 10}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-3\"></a>\n",
        "\n",
        "## 3. Converting API results into a DataFrame\n",
        "\n",
        "We define a `jsearch_to_dataframe` function that converts the raw list of job dictionaries into a pandas DataFrame. It keeps only the fields relevant to our analysis and adds helper columns (`country_code`, `country_name`, `search_role`, `data_source`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "KEEP_FIELDS = [\n",
        "    \"job_id\",\n",
        "    \"job_title\",\n",
        "    \"job_description\",\n",
        "    \"employer_name\",\n",
        "    \"employer_website\",\n",
        "    \"employer_company_type\",\n",
        "    \"job_publisher\",\n",
        "    \"job_employment_type\",\n",
        "    \"job_is_remote\",\n",
        "    \"job_apply_link\",\n",
        "    \"job_city\",\n",
        "    \"job_state\",\n",
        "    \"job_country\",\n",
        "    \"job_latitude\",\n",
        "    \"job_longitude\",\n",
        "    \"job_posted_at_datetime_utc\",\n",
        "    \"job_min_salary\",\n",
        "    \"job_max_salary\",\n",
        "    \"job_salary_currency\",\n",
        "    \"job_salary_period\",\n",
        "    \"job_required_experience\",\n",
        "    \"job_required_skills\",\n",
        "    \"job_required_education\",\n",
        "    \"job_highlights\",\n",
        "    \"job_posting_language\",\n",
        "]\n",
        "\n",
        "\n",
        "def jsearch_to_dataframe(\n",
        "    jobs: list,\n",
        "    country_code: str,\n",
        "    country_name: str,\n",
        "    role_query: str,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert a list of JSearch job results into a pandas DataFrame\n",
        "    and add helper columns for country and role.\n",
        "    \"\"\"\n",
        "    if not jobs:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.DataFrame(jobs)\n",
        "\n",
        "    # Keep only relevant fields (skip any that are missing)\n",
        "    available = [col for col in KEEP_FIELDS if col in df.columns]\n",
        "    df = df[available].copy()\n",
        "\n",
        "    # Add helper columns\n",
        "    df[\"country_code\"] = country_code\n",
        "    df[\"country_name\"] = country_name\n",
        "    df[\"search_role\"] = role_query\n",
        "    df[\"data_source\"] = \"jsearch\"\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-4\"></a>\n",
        "\n",
        "## 4. Fetching data for all location-role combinations and saving to CSV\n",
        "\n",
        "We loop over all location-role combinations, call `fetch_jsearch_jobs` for each, and combine the results. Since different city queries within the same country may return overlapping postings, we deduplicate by `job_id` at the end. The combined dataset is saved as a single CSV file.\n",
        "\n",
        "A 10-second pause between combos helps avoid hitting the hourly rate limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[1/36] 'data analyst' in New York (us)\n",
            "============================================================\n",
            "  [Quota] 197/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[2/36] 'junior data analyst' in New York (us)\n",
            "============================================================\n",
            "  [Quota] 194/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[3/36] 'data analyst' in California (us)\n",
            "============================================================\n",
            "  [Quota] 191/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[4/36] 'junior data analyst' in California (us)\n",
            "============================================================\n",
            "  [Quota] 188/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[5/36] 'data analyst' in Texas (us)\n",
            "============================================================\n",
            "  [Quota] 185/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 179/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 26 jobs (total: 56)\n",
            "  Rows received: 56\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[6/36] 'junior data analyst' in Texas (us)\n",
            "============================================================\n",
            "  [Quota] 176/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 27 jobs (total: 27)\n",
            "  Rows received: 27\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[7/36] 'data analyst' in Illinois (us)\n",
            "============================================================\n",
            "  [Quota] 173/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 167/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 27 jobs (total: 57)\n",
            "  Rows received: 57\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[8/36] 'junior data analyst' in Illinois (us)\n",
            "============================================================\n",
            "  [Quota] 164/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 28 jobs (total: 28)\n",
            "  Rows received: 28\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[9/36] 'data analyst' in Florida (us)\n",
            "============================================================\n",
            "  [Quota] 161/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 155/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 29 jobs (total: 59)\n",
            "  Rows received: 59\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[10/36] 'junior data analyst' in Florida (us)\n",
            "============================================================\n",
            "  [Quota] 152/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 28 jobs (total: 28)\n",
            "  Rows received: 28\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[11/36] 'data analyst' in Virginia (us)\n",
            "============================================================\n",
            "  [Quota] 149/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 143/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 25 jobs (total: 55)\n",
            "  Rows received: 55\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[12/36] 'junior data analyst' in Virginia (us)\n",
            "============================================================\n",
            "  [Quota] 140/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[13/36] 'data analyst' in Massachusetts (us)\n",
            "============================================================\n",
            "  [Quota] 137/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 131/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 29 jobs (total: 59)\n",
            "  Rows received: 59\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[14/36] 'junior data analyst' in Massachusetts (us)\n",
            "============================================================\n",
            "  [Quota] 128/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 122/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 27 jobs (total: 57)\n",
            "  Rows received: 57\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[15/36] 'data analyst' in Georgia (us)\n",
            "============================================================\n",
            "  [Quota] 119/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[16/36] 'junior data analyst' in Georgia (us)\n",
            "============================================================\n",
            "  [Quota] 116/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 26 jobs (total: 26)\n",
            "  Rows received: 26\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[17/36] 'data analyst' in Colorado (us)\n",
            "============================================================\n",
            "  [Quota] 113/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 107/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 24 jobs (total: 54)\n",
            "  Rows received: 54\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[18/36] 'junior data analyst' in Colorado (us)\n",
            "============================================================\n",
            "  [Quota] 104/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[19/36] 'data analyst' in remote USA (us)\n",
            "============================================================\n",
            "  [Quota] 101/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 96/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 21 jobs (total: 51)\n",
            "  Rows received: 51\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[20/36] 'junior data analyst' in remote USA (us)\n",
            "============================================================\n",
            "  [Quota] 94/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 22 jobs (total: 22)\n",
            "  Rows received: 22\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[21/36] 'data analyst' in London (gb)\n",
            "============================================================\n",
            "  [Quota] 91/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 28 jobs (total: 28)\n",
            "  Rows received: 28\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[22/36] 'junior data analyst' in London (gb)\n",
            "============================================================\n",
            "  [Quota] 88/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 27 jobs (total: 27)\n",
            "  Rows received: 27\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[23/36] 'data analyst' in Manchester (gb)\n",
            "============================================================\n",
            "  [Quota] 87/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 10 jobs (total: 10)\n",
            "  Rows received: 10\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[24/36] 'junior data analyst' in Manchester (gb)\n",
            "============================================================\n",
            "  [Quota] 84/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 27 jobs (total: 27)\n",
            "  Rows received: 27\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[25/36] 'data analyst' in Birmingham UK (gb)\n",
            "============================================================\n",
            "  [Quota] 81/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 26 jobs (total: 26)\n",
            "  Rows received: 26\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[26/36] 'junior data analyst' in Birmingham UK (gb)\n",
            "============================================================\n",
            "  [Quota] 78/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 28 jobs (total: 28)\n",
            "  Rows received: 28\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[27/36] 'data analyst' in Edinburgh (gb)\n",
            "============================================================\n",
            "  [Quota] 75/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[28/36] 'junior data analyst' in Edinburgh (gb)\n",
            "============================================================\n",
            "  [Quota] 72/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 28 jobs (total: 28)\n",
            "  Rows received: 28\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[29/36] 'data analyst' in remote UK (gb)\n",
            "============================================================\n",
            "  [Quota] 69/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 64/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 19 jobs (total: 49)\n",
            "  Rows received: 49\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[30/36] 'junior data analyst' in remote UK (gb)\n",
            "============================================================\n",
            "  [Quota] 61/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 55/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 28 jobs (total: 58)\n",
            "  Rows received: 58\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[31/36] 'data analyst' in Toronto (ca)\n",
            "============================================================\n",
            "  [Quota] 52/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 46/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 28 jobs (total: 58)\n",
            "  Rows received: 58\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[32/36] 'junior data analyst' in Toronto (ca)\n",
            "============================================================\n",
            "  [Quota] 43/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 37/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 23 jobs (total: 53)\n",
            "  Rows received: 53\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[33/36] 'data analyst' in Vancouver (ca)\n",
            "============================================================\n",
            "  [Quota] 34/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 28 jobs (total: 28)\n",
            "  Rows received: 28\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[34/36] 'junior data analyst' in Vancouver (ca)\n",
            "============================================================\n",
            "  [Quota] 31/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 29 jobs (total: 29)\n",
            "  Rows received: 29\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[35/36] 'data analyst' in remote Canada (ca)\n",
            "============================================================\n",
            "  [Quota] 28/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 30 jobs (total: 30)\n",
            "  [Quota] 23/200 requests remaining\n",
            "  Page 4 (num_pages=3): received 25 jobs (total: 55)\n",
            "  Rows received: 55\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "[36/36] 'junior data analyst' in remote Canada (ca)\n",
            "============================================================\n",
            "  [Quota] 22/200 requests remaining\n",
            "  Page 1 (num_pages=3): received 10 jobs (total: 10)\n",
            "  Rows received: 10\n",
            "  Pausing 10s...\n",
            "\n",
            "============================================================\n",
            "Collection complete. Combinations processed: 36\n",
            "============================================================\n",
            "\n",
            "Total rows before dedup: 1325\n",
            "Duplicates removed:     97\n",
            "Unique jobs kept:       1228\n",
            "\n",
            "Saved to: ../data/raw/jsearch_all_countries_roles.csv\n"
          ]
        }
      ],
      "source": [
        "RAW_DATA_DIR = \"../data/raw\"\n",
        "os.makedirs(RAW_DATA_DIR, exist_ok=True)\n",
        "\n",
        "SAVE_PATH = os.path.join(RAW_DATA_DIR, \"jsearch_all_countries_roles.csv\")\n",
        "PAUSE_BETWEEN_COMBOS = 10\n",
        "\n",
        "all_dfs = []\n",
        "total_combos = len(LOCATIONS) * len(ROLES)\n",
        "combo_num = 0\n",
        "\n",
        "for country_code, country_name, location, api_country in LOCATIONS:\n",
        "    for role in ROLES:\n",
        "        combo_num += 1\n",
        "        query = f\"{role} in {location}\"\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"[{combo_num}/{total_combos}] '{role}' in {location} ({country_code})\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        jobs = fetch_jsearch_jobs(\n",
        "            query=query,\n",
        "            num_pages=NUM_PAGES,\n",
        "            date_posted=DATE_POSTED,\n",
        "            country=api_country,\n",
        "        )\n",
        "\n",
        "        df = jsearch_to_dataframe(\n",
        "            jobs=jobs,\n",
        "            country_code=country_code,\n",
        "            country_name=country_name,\n",
        "            role_query=role,\n",
        "        )\n",
        "\n",
        "        print(f\"  Rows received: {len(df)}\")\n",
        "        if not df.empty:\n",
        "            all_dfs.append(df)\n",
        "\n",
        "        print(f\"  Pausing {PAUSE_BETWEEN_COMBOS}s...\")\n",
        "        time.sleep(PAUSE_BETWEEN_COMBOS)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Collection complete. Combinations processed: {combo_num}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Combine and deduplicate\n",
        "if all_dfs:\n",
        "    full_df = pd.concat(all_dfs, ignore_index=True)\n",
        "    before_dedup = len(full_df)\n",
        "    full_df = full_df.drop_duplicates(subset=[\"job_id\"], keep=\"first\")\n",
        "    after_dedup = len(full_df)\n",
        "\n",
        "    print(f\"\\nTotal rows before dedup: {before_dedup}\")\n",
        "    print(f\"Duplicates removed:     {before_dedup - after_dedup}\")\n",
        "    print(f\"Unique jobs kept:       {after_dedup}\")\n",
        "\n",
        "    full_df.to_csv(SAVE_PATH, index=False)\n",
        "    print(f\"\\nSaved to: {SAVE_PATH}\")\n",
        "else:\n",
        "    print(\"\\nNo data collected.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-5\"></a>\n",
        "\n",
        "## 5. Quick sanity checks on the combined dataset\n",
        "\n",
        "We load the saved CSV and inspect:\n",
        "- Shape (rows and columns);\n",
        "- First few rows;\n",
        "- Job counts per country and role;\n",
        "- Date range of collected postings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined dataset shape: (1228, 23)\n",
            "\n",
            "Columns: ['job_id', 'job_title', 'job_description', 'employer_name', 'employer_website', 'job_publisher', 'job_employment_type', 'job_is_remote', 'job_apply_link', 'job_city', 'job_state', 'job_country', 'job_latitude', 'job_longitude', 'job_posted_at_datetime_utc', 'job_min_salary', 'job_max_salary', 'job_salary_period', 'job_highlights', 'country_code', 'country_name', 'search_role', 'data_source']\n"
          ]
        }
      ],
      "source": [
        "combined_path = os.path.join(RAW_DATA_DIR, \"jsearch_all_countries_roles.csv\")\n",
        "combined_df = pd.read_csv(combined_path)\n",
        "\n",
        "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
        "print(f\"\\nColumns: {list(combined_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_id</th>\n",
              "      <th>job_title</th>\n",
              "      <th>job_description</th>\n",
              "      <th>employer_name</th>\n",
              "      <th>employer_website</th>\n",
              "      <th>job_publisher</th>\n",
              "      <th>job_employment_type</th>\n",
              "      <th>job_is_remote</th>\n",
              "      <th>job_apply_link</th>\n",
              "      <th>job_city</th>\n",
              "      <th>...</th>\n",
              "      <th>job_longitude</th>\n",
              "      <th>job_posted_at_datetime_utc</th>\n",
              "      <th>job_min_salary</th>\n",
              "      <th>job_max_salary</th>\n",
              "      <th>job_salary_period</th>\n",
              "      <th>job_highlights</th>\n",
              "      <th>country_code</th>\n",
              "      <th>country_name</th>\n",
              "      <th>search_role</th>\n",
              "      <th>data_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hDcRNAz4ev12li_ZAAAAAA==</td>\n",
              "      <td>Data Analyst</td>\n",
              "      <td>Join a newly created team dedicated to the Dis...</td>\n",
              "      <td>Disney Direct to Consumer</td>\n",
              "      <td>https://disney.fandom.com</td>\n",
              "      <td>Disney Careers</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>False</td>\n",
              "      <td>https://www.disneycareers.com/en/job/new-york/...</td>\n",
              "      <td>New York</td>\n",
              "      <td>...</td>\n",
              "      <td>-74.005973</td>\n",
              "      <td>2026-02-12T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'Qualifications': ['3+ years of relevant expe...</td>\n",
              "      <td>us</td>\n",
              "      <td>USA</td>\n",
              "      <td>data analyst</td>\n",
              "      <td>jsearch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>YBGg4U6cLzfYcc2VAAAAAA==</td>\n",
              "      <td>Entry Level Human Resources &amp; Data Analyst</td>\n",
              "      <td>Top-Tier Bank in Midtown, Manhattan is seeking...</td>\n",
              "      <td>Social Capital Resources</td>\n",
              "      <td>NaN</td>\n",
              "      <td>LinkedIn</td>\n",
              "      <td>Contractor</td>\n",
              "      <td>False</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/entry-level...</td>\n",
              "      <td>New York</td>\n",
              "      <td>...</td>\n",
              "      <td>-74.005973</td>\n",
              "      <td>2026-02-17T17:00:00.000Z</td>\n",
              "      <td>25.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>HOUR</td>\n",
              "      <td>{'Qualifications': ['0-1 years previous experi...</td>\n",
              "      <td>us</td>\n",
              "      <td>USA</td>\n",
              "      <td>data analyst</td>\n",
              "      <td>jsearch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wyxH_fGPJReWty01AAAAAA==</td>\n",
              "      <td>Associate Data Analyst, DX Research</td>\n",
              "      <td>Overview\\n\\nAbout DX\\n\\nDX is one of the faste...</td>\n",
              "      <td>Atlassian</td>\n",
              "      <td>https://www.atlassian.com</td>\n",
              "      <td>LinkedIn</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>True</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/associate-d...</td>\n",
              "      <td>New York</td>\n",
              "      <td>...</td>\n",
              "      <td>-74.005973</td>\n",
              "      <td>2026-02-14T00:00:00.000Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'Qualifications': ['4+ years of experience in...</td>\n",
              "      <td>us</td>\n",
              "      <td>USA</td>\n",
              "      <td>data analyst</td>\n",
              "      <td>jsearch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     job_id                                   job_title  \\\n",
              "0  hDcRNAz4ev12li_ZAAAAAA==                                Data Analyst   \n",
              "1  YBGg4U6cLzfYcc2VAAAAAA==  Entry Level Human Resources & Data Analyst   \n",
              "2  wyxH_fGPJReWty01AAAAAA==         Associate Data Analyst, DX Research   \n",
              "\n",
              "                                     job_description  \\\n",
              "0  Join a newly created team dedicated to the Dis...   \n",
              "1  Top-Tier Bank in Midtown, Manhattan is seeking...   \n",
              "2  Overview\\n\\nAbout DX\\n\\nDX is one of the faste...   \n",
              "\n",
              "               employer_name           employer_website   job_publisher  \\\n",
              "0  Disney Direct to Consumer  https://disney.fandom.com  Disney Careers   \n",
              "1   Social Capital Resources                        NaN        LinkedIn   \n",
              "2                  Atlassian  https://www.atlassian.com        LinkedIn   \n",
              "\n",
              "  job_employment_type  job_is_remote  \\\n",
              "0           Full-time          False   \n",
              "1          Contractor          False   \n",
              "2           Full-time           True   \n",
              "\n",
              "                                      job_apply_link  job_city  ...  \\\n",
              "0  https://www.disneycareers.com/en/job/new-york/...  New York  ...   \n",
              "1  https://www.linkedin.com/jobs/view/entry-level...  New York  ...   \n",
              "2  https://www.linkedin.com/jobs/view/associate-d...  New York  ...   \n",
              "\n",
              "  job_longitude job_posted_at_datetime_utc  job_min_salary  job_max_salary  \\\n",
              "0    -74.005973   2026-02-12T00:00:00.000Z             NaN             NaN   \n",
              "1    -74.005973   2026-02-17T17:00:00.000Z            25.0            32.0   \n",
              "2    -74.005973   2026-02-14T00:00:00.000Z             NaN             NaN   \n",
              "\n",
              "  job_salary_period                                     job_highlights  \\\n",
              "0               NaN  {'Qualifications': ['3+ years of relevant expe...   \n",
              "1              HOUR  {'Qualifications': ['0-1 years previous experi...   \n",
              "2               NaN  {'Qualifications': ['4+ years of experience in...   \n",
              "\n",
              "   country_code country_name   search_role data_source  \n",
              "0            us          USA  data analyst     jsearch  \n",
              "1            us          USA  data analyst     jsearch  \n",
              "2            us          USA  data analyst     jsearch  \n",
              "\n",
              "[3 rows x 23 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jobs per country and role:\n",
            "country_code         search_role  n_jobs\n",
            "          ca        data analyst     131\n",
            "          ca junior data analyst      80\n",
            "          gb        data analyst     138\n",
            "          gb junior data analyst     139\n",
            "          us        data analyst     471\n",
            "          us junior data analyst     269\n"
          ]
        }
      ],
      "source": [
        "# Jobs count per country and role\n",
        "print(\"Jobs per country and role:\")\n",
        "print(\n",
        "    combined_df\n",
        "    .groupby([\"country_code\", \"search_role\"])\n",
        "    .size()\n",
        "    .reset_index(name=\"n_jobs\")\n",
        "    .to_string(index=False)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Earliest posting: 2026-01-18 00:00:00+00:00\n",
            "Latest posting:   2026-02-17 18:00:00+00:00\n"
          ]
        }
      ],
      "source": [
        "# Date range of collected postings\n",
        "combined_df[\"job_posted_at_datetime_utc\"] = pd.to_datetime(\n",
        "    combined_df[\"job_posted_at_datetime_utc\"]\n",
        ")\n",
        "print(f\"Earliest posting: {combined_df['job_posted_at_datetime_utc'].min()}\")\n",
        "print(f\"Latest posting:   {combined_df['job_posted_at_datetime_utc'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"section-6\"></a>\n",
        "\n",
        "## 6. Summary\n",
        "\n",
        "During the data collection stage, the following steps were performed:\n",
        "\n",
        "- **Fetch function:** A `fetch_jsearch_jobs` function was defined to request job postings from the JSearch API (via RapidAPI), with pagination, real-time quota logging, and automatic stop on HTTP 429 rate limits.\n",
        "- **Collection settings:** Target countries (USA, UK, Canada) and roles (*data analyst*, *junior data analyst*) were defined. Queries were split by major cities and states within each country to maximise coverage, since Google for Jobs returns ~50–100 results per unique query.\n",
        "- **Result conversion:** A `jsearch_to_dataframe` function was defined to convert the raw API response list into a pandas DataFrame and to add columns `country_code`, `country_name`, `search_role`, and `data_source` for later filtering and grouping.\n",
        "- **Data collection and saving:** For each location-role combination, job postings were fetched, converted to a DataFrame, and combined. Duplicates from overlapping city queries were removed by `job_id`. A single combined file, **jsearch_all_countries_roles.csv**, was saved for use in the next notebook.\n",
        "- **Sanity checks:** The combined dataset was loaded and briefly inspected (shape, head, and counts by country and role) to confirm that collection completed as expected.\n",
        "\n",
        "The raw data is stored in `data/raw/` and is ready for cleaning and skill extraction in the next notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "job-skills",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
